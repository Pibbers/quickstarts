= Utilizar Apache Airflow con Teradata Vantage
:page-lang: es
:experimental:
:page-author: Satish Chinthanippu
:page-email: satish.chinthanippu@teradata.com
:page-revdate: 6 de febrero de 2024
:description: Utilice Apache Airflow con Teradata Vantage.
:keywords: almacenes de datos, separación de almacenamiento informático, teradata, vantage, plataforma de datos en la nube, almacenamiento de objetos, inteligencia empresarial, análisis empresarial, elt, airflow, flujo de trabajo.
:tabs:
:dir: airflow

== Descripción general

Este tutorial demuestra cómo utilizar Airflow con Teradata Vantage. Airflow se instalará en el sistema Ubuntu.

== Requisitos previos

* Ubuntu 22.x 
* Acceso a una instancia de Teradata Vantage.
+
include::../partials/vantage_clearscape_analytics.adoc[]
* Python *3.8*, *3.9*, *3.10* o *3.11* instalado.

== Instalar Apache Airflow

1. Configure la variable de entorno AIRFLOW_HOME. Airflow requiere un directorio de inicio y usa ~/airflow de forma predeterminada, pero puede establecer una ubicación diferente si lo prefiere. La variable de entorno AIRFLOW_HOME se utiliza para informar a Airflow de la ubicación deseada.
+
[source, bash]
----
export AIRFLOW_HOME=~/airflow
----
2. Instale la versión estable 2.8.1 de `apache-airflow` desde el repositorio de PyPI:
+
[source, bash]
----
AIRFLOW_VERSION=2.8.1
PYTHON_VERSION="$(python --version | cut -d " " -f 2 | cut -d "." -f 1-2)"
CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"
pip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"
----
3. Instale la versión estable 1.0.0 del proveedor de Airflow Teradata desde el repositorio de PyPI.
+
[source, bash]
----
pip install "apache-airflow-providers-teradata==1.0.0"
----

== Iniciar Airflow independiente

1. Ejecute Airflow de forma independiente
+
[source, bash]
----
airflow standalone
----
2. Acceda a la interfaz de usuario de Airflow. Visite https://localhost:8080 en el navegador e inicie sesión con los detalles de la cuenta de administrador que se muestran en el terminal.

== Definir una conexión Teradata en la interfaz de usuario de Airflow

1. Abra la sección Administración -> Conexiones de la interfaz de usuario. Haga clic en el enlace Crear para crear una nueva conexión.
+
image::{dir}/airflow-connection.png[Menú desplegable de administración de Airflow, width=75%]
2. Complete los detalles de entrada en la página Nueva conexión.
+
image::{dir}/airflow-newconnection.png[Nueva conexión de Airflow, width=75%]
* ID de conexión: ID único de la conexión Teradata.
* Tipo de conexión: tipo de sistema. Seleccione Teradata.
* URL del servidor de base de datos (obligatorio): nombre de host de la instancia de Teradata al que conectarse.
* Base de datos (opcional): especifique el nombre de la base de datos a la que conectarse
* Iniciar sesión (obligatorio): especifique el nombre de usuario para conectarse.
* Contraseña (obligatoria): especifique la contraseña para conectarse.
* Haga clic en Probar y guardar.

== Definir un DAG en Airflow

1. En Airflow, los DAG se definen como código Python.
2. Cree un DAG como un archivo de Python como sample.py en el directorio DAG_FOLDER - $AIRFLOW_HOME/files/dags.
+
[source, python]
----
from datetime import datetime
from airflow import DAG
from airflow.providers.teradata.operators.teradata import TeradataOperator
CONN_ID = "Teradata_TestConn"
with DAG(
    dag_id="example_teradata_operator",
    max_active_runs=1,
    max_active_tasks=3,
    catchup=False,
    start_date=datetime(2023, 1, 1),
) as dag:
    create = TeradataOperator(
        task_id="table_create",
        conn_id=CONN_ID,
        sql="""
            CREATE TABLE my_users,
            FALLBACK (
                user_id decimal(10,0) NOT NULL GENERATED ALWAYS AS IDENTITY (
                    START WITH 1
                    INCREMENT BY 1
                    MINVALUE 1
                    MAXVALUE 2147483647
                    NO CYCLE),
                user_name VARCHAR(30)
            ) PRIMARY INDEX (user_id);
        """,
    )
----

== Cargar DAG

Airflow carga DAG desde archivos fuente de Python, que busca dentro de su directorio DAG_FOLDER - $AIRFLOW_HOME/files/dags configurado.

== Ejecutar DAG
Los DAG se ejecutarán de dos maneras:
1. Cuando se activen manualmente o mediante la API
2. En una programación definida, que se define como parte del DAG
`example_teradata_operator` se define para activarse manualmente. Para definir una programación, cualquier valor de programación de link:https://en.wikipedia.org/wiki/Cron[Crontab, window="_blank"] válida se puede pasar al argumento de programación.
[source, python]
----
with DAG(
  dag_id="my_daily_dag",
  schedule="0 0 * * *"
  ) as dag:
----

== Resumen

Este tutorial demostró cómo utilizar Airflow y el proveedor de Airflow Teradata con una instancia de Teradata Vantage. El DAG de ejemplo proporcionado crea la tabla `my_users` en la instancia de Teradata Vantage definida en la interfaz de usuario de Connection. 

== Otras lecturas
* link:https://airflow.apache.org/docs/apache-airflow/stable/start.html[Documentación de Airflow]
* link:https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html[DAG de Airflow]


include::../partials/community_link.adoc[]
